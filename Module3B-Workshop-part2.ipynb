{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ann_visualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3B: Advanced Numerical Techniques and Potential Ethical Concerns (part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# Numerical Data Manipulation libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as stat\n",
    "\n",
    "# Figure Plotting libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# Naive Bayes libraries\n",
    "import sklearn\n",
    "from sklearn.naive_bayes import BernoulliNB      # Naive Bayes Classifier based on a Bernoulli Distribution\n",
    "from sklearn.naive_bayes import GaussianNB       # Naive Bayes Classifier based on a Gaussian Distribution\n",
    "from sklearn.naive_bayes import MultinomialNB    # Naive Bayes Classifier based on a Multinomial Distribution\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Text Analysis libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict( model, image, print_img ):\n",
    "    \n",
    "    if( print_img ):\n",
    "        plt.grid(b=None)\n",
    "        plt.imshow(image)\n",
    "    \n",
    "    n_image = np.expand_dims(image, axis=0)\n",
    "    n_image = np.expand_dims(n_image, axis=3)\n",
    "    \n",
    "    prediction = model.predict( n_image )[0]\n",
    "    \n",
    "    if( prediction >= 0.5 ):\n",
    "        if( print_img ):\n",
    "            print('Model Prediction: CRIMINAL with probability = %.2f' % prediction)\n",
    "        result = 1\n",
    "    else:\n",
    "        if( print_img ):\n",
    "            print('Model Prediction: NOT CRIMINAL with probability = %.2f' % prediction)\n",
    "        result = 0\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks for Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the workshop, we will see how we can apply the principles of Deep Learning to more complex datasets, like images.\n",
    "\n",
    "Let's suppose that we have a dataset with faces of people with / and without crimial records. Like the paper that was presented in last workshop, we are going to try to use a very simple neural network to try to find patterns in faces that are considered criminals from those who are not.\n",
    "\n",
    "Note: this is a toy dataset. It does not represent any reality. We collected a public research dataset with human faces and randomly labelled them as *Criminal* and *Not Criminal* for learning purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_dataset = pd.read_csv('data/dataset_64.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of images in dataset:\n",
    "num_images = len(faces_dataset)\n",
    "num_pixels = len(faces_dataset.columns) - 1\n",
    "\n",
    "print('Total number of images in the dataset is: ' + str(num_images))\n",
    "print('Total number of pixels per image is: ' + str(num_pixels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also try to understand what is the distribution of criminals / not crimials in our dataset:\n",
    "criminals = faces_dataset[ faces_dataset['target'] == 1 ]\n",
    "not_criminals = faces_dataset[ faces_dataset['target'] == 0 ]\n",
    "\n",
    "print('Criminality distribution:')\n",
    "print('Number of criminals: ' + str(len(criminals)))\n",
    "print('Number of not criminals: ' + str(len(not_criminals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is a set of pixels. More precesely, each image corresponds to a row and each image contains a total of 9216 pixels. This means that the image has a size of 96x96. The last colum **target** specifies if the face is associated to someone who has crimial records *target=1* or to someone who does not have any crminal records *target=0*.\n",
    "\n",
    "Let's see if we can visualize the images..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting some images... \n",
    "from skimage.transform import resize\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "indx = 2\n",
    "image_0 = faces_dataset.iloc[indx,0:num_pixels]\n",
    "\n",
    "# image_0 is a vector with 9216 pixels. In order to convert it into an image,\n",
    "# we need to reshape this vector into a matrix of 96*96 = 9216 pixels\n",
    "\n",
    "image_0 =  np.array(image_0)\n",
    "image_0 = np.reshape(image_0, (64, 64))\n",
    "image_0 = resize(image_0, (128, 128), anti_aliasing=True)\n",
    "\n",
    "# show image\n",
    "plt.imshow(image_0,  cmap=plt.cm.gray )\n",
    "\n",
    "# print target\n",
    "if( faces_dataset.iloc[indx,num_pixels] == 1):\n",
    "    print('Image label = CRIMINAL')\n",
    "else:\n",
    "    print('Image label = NOT CRIMINAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning for Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach we are going to use for facial recognition is very straight forward but you could check this out in the case of a very complicated problem. Let’s learn how modern face recognition works!\n",
    "\n",
    "The goal here is to get deep neural network to output a person’s face with identification. This means that the neural network needs to be trained to automatically identify different features of a face and calculate numbers based on that. The output of the neural network can be thought of as an identifier for a particular person's face: in this case, if the person represents a criminal or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, a Convolutional Neural Network (CNN or ConvNet) is a class of artificial neural networks that has successfully been applied to analyzing visual imagery. They have applications in image recognition (facial recognition) and video analysis, recommender systems and natural language processing. Here, facial recognition would be analysed.\n",
    "\n",
    "The name *convolutional* comes preisely from a mathematical operation that is called the *convolution operator*. This operator is able to convolute an image based on a kernel, which can detect vertical edges, horizontal edges,faces, eyes, etc. The following figure shows an example of a convolution:\n",
    "\n",
    "<img src='https://s3-us-west-2.amazonaws.com/static.pyimagesearch.com/keras-conv2d/keras_conv2d_padding.gif' />\n",
    "A 3×3 kernel applied to an image. This animation was contributed to StackOverflow (<a href=\"https://stackoverflow.com/questions/52067833/how-to-plot-an-animated-matrix-in-matplotlib\">source</a>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for curiosity, the convolution is highly used in edge detection, we can do this in the following way:\n",
    "   \n",
    "<img src=\"images/edge.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = []\n",
    "\n",
    "WIDTH = 64\n",
    "HEIGHT = 64\n",
    "\n",
    "data = faces_dataset.iloc[:,0:num_pixels]\n",
    "for indx in range(0, len(data)):\n",
    "    \n",
    "    image = np.array(data.iloc[indx,0:num_pixels])\n",
    "    temp = np.reshape(image, (WIDTH, HEIGHT))  \n",
    "    temp = np.reshape(image, (WIDTH, HEIGHT))/255.0\n",
    "    all_images.append(temp)\n",
    "\n",
    "# convert structure to array\n",
    "all_images = np.array(all_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate your dataset: \n",
    "# put the variable that you wish to classify (the target) in one variable\n",
    "# put your features (the pixels) in another variable\n",
    "X=np.zeros((num_images,WIDTH,HEIGHT,1))\n",
    "X[:,:,:,0]=all_images\n",
    "y = faces_dataset.iloc[:,num_pixels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the dataset into test set and train set\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model_deep = Sequential()\n",
    "\n",
    "# add layers\n",
    "model_deep.add(Conv2D(64, (3, 3), padding = 'same', activation='relu', input_shape=(WIDTH, HEIGHT, 1)))\n",
    "model_deep.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model_deep.add(Dropout(0.25))\n",
    "\n",
    "model_deep.add(Conv2D(32, (3, 3), padding = 'same', activation='relu', input_shape=(WIDTH, HEIGHT, 1)))\n",
    "model_deep.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model_deep.add(Dropout(0.25))\n",
    "model_deep.add(Flatten())\n",
    "\n",
    "model_deep.add(Dense(256, activation='tanh'))\n",
    "\n",
    "model_deep.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "# SGD = Stochastic Gradient Descent\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_deep.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ann_visualizer.visualize import ann_viz;\n",
    "ann_viz(model_deep, view=True, filename='convolution', title=\"convolution_net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "history_deep = model_deep.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "_, train_acc_deep = model_deep.evaluate(X_train, y_train, verbose=0)\n",
    "_, test_acc_deep = model_deep.evaluate(X_test, y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc_deep, test_acc_deep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training history\n",
    "pyplot.plot(history_deep.history['acc'], label='train')\n",
    "pyplot.plot(history_deep.history['val_acc'], label='test')\n",
    "pyplot.ylabel('accuracy', fontsize=12)\n",
    "pyplot.xlabel('iterations', fontsize=12)\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = 0\n",
    "image = all_images[indx,:,:]\n",
    "predict( model_deep, image, True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = 1\n",
    "image = all_images[indx,:,:]\n",
    "predict( model_deep, image, True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the same thing, but without using the convolutional networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Without convulutional networks:\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten(input_shape=(WIDTH, HEIGHT,1)))\n",
    "model.add(Dense(256, activation='tanh'))\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "model.add(Dense(32, activation='tanh'))\n",
    "model.add(Dense(16, activation='tanh'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
    "_, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training history\n",
    "pyplot.plot(history.history['acc'], label='train')\n",
    "pyplot.plot(history.history['val_acc'], label='test')\n",
    "pyplot.ylabel('accuracy', fontsize=12)\n",
    "pyplot.xlabel('iterations', fontsize=12)\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = 0\n",
    "image = all_images[indx,:,:]\n",
    "\n",
    "predict( model, image, True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = 1\n",
    "image = all_images[indx,:,:]\n",
    "\n",
    "predict( model, image, True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also make an analysis of your results in terms of different evaluation metrics by calling the function *classification_report*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "results = []\n",
    "for indx in range(0, len(X_test)):\n",
    "    \n",
    "    image = X_test[indx,:,:,0]\n",
    "    r = predict( model_deep, image, False )\n",
    "    results.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=['NOT CRIMINAL', 'CRIMINAL']\n",
    "print(classification_report(y_test.values, results, target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also visuallize this, using the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mat = confusion_matrix(y_test, results)\n",
    "sns.heatmap(mat.T, square=True, fmt='d', cbar=True, xticklabels=names, \\\n",
    "            yticklabels=names, annot=True)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it Yourself!\n",
    "\n",
    "Upload a picture of a face (it can be you) and use the models to make predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import misc\n",
    "\n",
    "# auxiliary function that converts an input image to the size 64x64 and to grayscale\n",
    "def convert_image( path ):\n",
    "    \n",
    "    # read image and convert to gray scale\n",
    "    image = misc.imread( path, mode=\"L\" )\n",
    "    \n",
    "    # reshape to size 64x64\n",
    "    image = resize(image, (64, 64), anti_aliasing=True)\n",
    "    \n",
    "    # return image\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE: upload an image for classification\n",
    "image_path = \n",
    "\n",
    "# convert the image using the function convert_image\n",
    "# YOUR CODE HERE\n",
    "test_image = \n",
    "\n",
    "# call the predict function using the deep learning model and your image\n",
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Discussion:\n",
    "\n",
    "- Q1. What is the major problem with the design of this model?\n",
    "\n",
    "\n",
    "- Q2. What are the major consequences of the application of this model if people use it as a black box?\n",
    "\n",
    "\n",
    "\n",
    "- Q3. How could we do this correctly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethical Concerns\n",
    "\n",
    "Let's imagine that a political consulting firm uses such algorithms to classify images of polticians and influencial religious leaders to help people understand if the person that they are voting or supporting is honest.\n",
    "\n",
    "Here are some controversial examples that our model classified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload an image for classification\n",
    "image_path = \"images/trump.jpg\"\n",
    "\n",
    "# convert the image using the function convert_image\n",
    "test_image = convert_image( image_path )\n",
    "\n",
    "# call the predict function using the deep learning model and your image\n",
    "p = predict( model_deep, test_image, True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload an image for classification\n",
    "image_path = \"images/putin.jpeg\"\n",
    "\n",
    "# convert the image using the function convert_image\n",
    "test_image = convert_image( image_path )\n",
    "\n",
    "# call the predict function using the deep learning model and your image\n",
    "p = predict( model_deep, test_image, True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload an image for classification\n",
    "image_path = \"images/pope.jpg\"\n",
    "\n",
    "# convert the image using the function convert_image\n",
    "test_image = convert_image( image_path )\n",
    "\n",
    "# call the predict function using the deep learning model and your image\n",
    "p = predict( model_deep, test_image, True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Discussion:\n",
    "\n",
    "Each group will have to identify at least one ethical concern of this problem. This ethical concern can be related to the impact of the model in society, in politics, religion, technology, business, etc...\n",
    "\n",
    "**Key points identified:**\n",
    "- **KP1**\n",
    "- **KP2**\n",
    "- **KP3**\n",
    "- **KP4**\n",
    "- **KP5**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Materials\n",
    "\n",
    "The literature of machine learning is generally surounded by two types of machine learning algorithms: neural networks and support vector machines. Support vector machines (SVMs) classify data using an optimization function: the idea is to compute the support vectors (the bourdaries) of the data and then find a hyperplane that can separate it. \n",
    "\n",
    "In Python, you can implement a SVM very quickly using all the knowledge of machine learninig that you learned so far. For the curious students, you can explore this technique for image classification, in the following book:\n",
    "\n",
    " Python Data Science Handbook by Jake VanderPlas\n",
    " \n",
    " You can find a very good explanation of SVMs and examples of application here: <a href=\"https://jakevdp.github.io/PythonDataScienceHandbook/05.07-support-vector-machines.html\">SVMs</a>\n",
    " \n",
    " The example covered is the classification of famous faces:\n",
    " \n",
    " <img src=\"images/svm.png\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
