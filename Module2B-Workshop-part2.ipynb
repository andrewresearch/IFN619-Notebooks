{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2B (Part 2): Bayesian Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Bayesian network (BN) is composed of random variables (nodes) and their conditional dependencies (arcs) which, together, form a directed acyclic graph (DAG). They have become a widely used method in the modelling of uncertain knowledge. A conditional probability table (CPT) is associated with each node. It contains the conditional probability distribution of the node given its parents in the DAG:\n",
    "\n",
    "<img src='images/Wetgrass.png' style='width: 450px;' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, each node represents a random variable, which is decribed by a probability distribution over its parents' nodes. The biggest advantage of the Bayesian network is its compact and modular strucute. Humans do not have access to all the probability distributions and all variables of the world. For this reason, in order to make probabilisitc inferences, humans need to combine different sources of evidence in order to come up with an answer. This is precisely what Bayesin Networks do, using elaborate probabilistic formulas based on the Naive Bayes that we jsut saw. It is not relevant to go through the mathematics. Bayesian Networks are graphical structures that enable any non-expert to use them in daily decision making tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Bayesian Network in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the Bayesian Network, which describes the following decision scenario. \n",
    "\n",
    "This network trys to expresss the probability of a person having wither Tuberculosis, Lung Cancer or Bronchitis, given some symptoms, Shortness in Breath (Dispnea), exames (like a positive xray result) and some historical information: visits to Asia and Smoking.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/asia.png' style='width: 450px;' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random variables of this network are:\n",
    "* Visit to Asia\n",
    "* Tuberculosis\n",
    "* Either Tuberculosi or Lung Cancer\n",
    "* Positive X-Ray\n",
    "* Dispnea\n",
    "* Bronchitis\n",
    "* Smoker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION. Which of the above random variables are root notes of the Network? (A root node is a node that does not descend from any other node)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "???\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Network Structure in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing into Python the necessary libraries to work in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "#Python Library that deals with Bayesan Networks (BNs)\n",
    "import pyAgrum as bn_graphs\n",
    "import pyAgrum.lib.notebook as gnb\n",
    "\n",
    "from pyAgrum.lib.bn2roc import showROC\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define our Bayesian Network. As wyou can see, it is an empty structure (for now...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = bn_graphs.BayesNet('CancerBN') #Creates an empty network called CancerBN\n",
    "print(bn)                           #Prints the created BN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code builds a general network structure, but with no nodes or edges or conditional probability tables.\n",
    "Our next step will be precisely to specify these variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Random Variables (the nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a random variable, we need to use pyAgrum's function *LabelizedVariable*, which is a variable whose domain is a finite set of labels. You can do it in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function LabelizedVariable( id_name, label, cardinality), receives the follwoing arguments\n",
    "#name: is a string that uniquely identifies the node\n",
    "#cardinality: is an integer which specifies the amount of different values that the \n",
    "#             the random varible will have. We will set this for 0 now\n",
    "\n",
    "id_name = 'LungCancer'\n",
    "label = 'LungCancer'\n",
    "LungCancer = bn_graphs.LabelizedVariable(id_name, label, 0)\n",
    "print(LungCancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now specify the labels \"true\" and \"false\" of our random variable. For this, we use the method *addLabel()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In our example, we have a random variable 'LungCancer' which can have the values \n",
    "LungCancer.addLabel('present')   #'present' if LungCancer occured or \n",
    "\n",
    "LungCancer.addLabel('absent')    #'absent' if LungCancer did not occur.\n",
    "print(LungCancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now add the created random variable to our network by using the method .add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn.add( LungCancer )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list with the names of the nodes\n",
    "nodes_lst = ['VisitAsia','Smoker', 'Tuberculosis', 'Bronchitis', 'Dispnea', 'PositiveXray', 'TubercOrLungCan']\n",
    "print(nodes_lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a new node for each of the random variables in nodes_lst\n",
    "\n",
    "# node is a variable  that will go through each entry of the list nodes_lst\n",
    "# the iterations are performed by the function *for* in the following way:\n",
    "# node = 'Visit Asia' ............. iteration #1\n",
    "# node = 'Smoker' ................. iteration #2\n",
    "# node = 'Tuberculosis' ........... iteration #3\n",
    "# node = 'Bronchitis' ............. iteration #4\n",
    "# node = 'Dispnea' ................ iteration #5\n",
    "# node = 'Positive Xray' .......... iteration #6\n",
    "# node = 'TubercOrLungCan' ........ iteration #7\n",
    "for node in nodes_lst:\n",
    "    print(node)\n",
    "    var = bn_graphs.LabelizedVariable(node, node, 0)  #creates random variable\n",
    "    var.addLabel('present')                           #adds the label 'true'\n",
    "    var.addLabel('absent')                            #adds the label 'false'\n",
    "    bn.add(var)                                       #adds the created var to the network\n",
    "\n",
    "print(bn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Edges (the arcs between nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined our nodes, we need to define the arcs between them. For this, we use the method addArc( sourceNode, targetNode ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arc between \n",
    "bn.addArc('VisitAsia', 'Tuberculosis')\n",
    "print(bn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_lst = [ ('Tuberculosis', 'TubercOrLungCan'), ('LungCancer', 'TubercOrLungCan'), ('Smoker','LungCancer' ), ('Smoker', 'Bronchitis'), ('Bronchitis', 'Dispnea'), ('TubercOrLungCan', 'Dispnea'), ('TubercOrLungCan', 'PositiveXray' ) ]\n",
    "print( arc_lst )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a new edge for each of the random variables in arc_lst\n",
    "\n",
    "# arc is a variable that will go through each entry of the list arc_lst\n",
    "# the iterations are performed by the function *for* in the following way:\n",
    "# arc = ('Tuberculosis', 'TubercOrLungCan') ............ iteration #1\n",
    "# arc = ('Lung Cancer', 'TubercOrLungCan') ............. iteration #2\n",
    "# arc = ('Smoker', 'Lung Cancer') ............. iteration #3\n",
    "# arc = ('Smoker', 'Bronchitis') ............. iteration #4\n",
    "# arc = ('Bronchitis', 'Dispnea') ............. iteration #5\n",
    "# arc = ('TubercOrLungCan', 'Dispnea') ............. iteration #6\n",
    "# arc = ('TubercOrLungCan', 'Positive Xray') ............. iteration #3\n",
    "for arc in arc_lst:\n",
    "    bn.addArc( arc[0],  arc[1] )      #adds the created arc to the network\n",
    "\n",
    "print(bn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display your Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Conditional Probability Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Onde we have the structure of the network, we need to specify the conditional probability tables (CPTs). In Python, each CPT is referred to as a *Potential*.\n",
    "\n",
    "There are several ways to fill these CPTs. In this workshop, we will show you some of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low Level Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling the conditional probability table of the root node: Burglary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill the conditional probability table of the variable \n",
    "#VisitAsia according to Figure 1: Pr(VisitAsia=present)  = 0.01\n",
    "#                                 Pr(VisitAsia=absent) = 1 - 0.01 = 0.99\n",
    "bn.cpt('VisitAsia').fillWith( [0.01, 1-0.01] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling the conditional probability table of the root node: Earthquake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the conditional probability table of the variable \n",
    "# Smoker according to Figure 1: Pr(Smoker=present)  = 0.5\n",
    "#                               Pr(Smoker=absent) = 1 - 0.5 = 0.5\n",
    "bn.cpt('Smoker').fillWith( [0.5, 1-0.5] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most convinient way to fill conditional probability tables is by using dictionaries in Python. This is done in the following way for variable TubercOrLungCan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn.cpt( 'TubercOrLungCan' )[ {'LungCancer': 'present',  'Tuberculosis': 'present'}  ] = [1, 0]\n",
    "bn.cpt( 'TubercOrLungCan' )[ {'LungCancer': 'present',  'Tuberculosis': 'absent'} ] = [1, 0]\n",
    "bn.cpt( 'TubercOrLungCan' )[ {'LungCancer': 'absent', 'Tuberculosis': 'present'}  ] = [1, 0]\n",
    "bn.cpt( 'TubercOrLungCan' )[ {'LungCancer': 'absent', 'Tuberculosis': 'absent'} ] = [0, 1]\n",
    "\n",
    "bn.cpt('TubercOrLungCan')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try it yourself!** Can you write down the conditional probability tables for the node JohnCalls according to the probabilities in Figure 1? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JohnCalls\n",
    "bn.cpt( 'Tuberculosis' )[ {'VisitAsia': 'present'}  ] = [ 0.05, 1 - 0.05  ]\n",
    "bn.cpt( 'Tuberculosis' )[ {'VisitAsia': 'absent'} ] = [ 0.01, 1 - 0.01 ]\n",
    "\n",
    "bn.cpt('Tuberculosis')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it yourself! Can you write down the conditional probability tables for the node MaryCalls according to the probabilities in Figure 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JohnCalls\n",
    "bn.cpt( 'LungCancer' )[ {'Smoker': 'present'}  ] = [ 0.1, 1 - 0.1  ]\n",
    "bn.cpt( 'LungCancer' )[ {'Smoker': 'absent'} ] = [ 0.01, 1 - 0.01 ]\n",
    "\n",
    "bn.cpt('LungCancer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bronchitis\n",
    "bn.cpt( 'Bronchitis' )[ {'Smoker': 'present'}  ] = [ 0.6, 1 - 0.6  ]\n",
    "bn.cpt( 'Bronchitis' )[ {'Smoker': 'absent'} ] = [ 0.3, 1 - 0.3 ]\n",
    "\n",
    "bn.cpt('Bronchitis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn.cpt( 'Dispnea' )[ {'Bronchitis': 'present',  'TubercOrLungCan': 'present'}  ] = [0.9, 1-0.9]\n",
    "bn.cpt( 'Dispnea' )[ {'Bronchitis': 'present',  'TubercOrLungCan': 'absent'} ] = [1, 0]\n",
    "bn.cpt( 'Dispnea' )[ {'Bronchitis': 'absent', 'TubercOrLungCan': 'present'}  ] = [0.7, 1-0.7]\n",
    "bn.cpt( 'Dispnea' )[ {'Bronchitis': 'absent', 'TubercOrLungCan': 'absent'} ] = [0.8, 1-0.8]\n",
    "\n",
    "bn.cpt('Dispnea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PositiveXray\n",
    "bn.cpt( 'PositiveXray' )[ {'TubercOrLungCan': 'present'}  ] = [ 0.6, 1 - 0.6  ]\n",
    "bn.cpt( 'PositiveXray' )[ {'TubercOrLungCan': 'absent'} ] = [ 0.3, 1 - 0.3 ]\n",
    "\n",
    "bn.cpt('PositiveXray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.showInference( bn )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving your Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done! Your network is now complete! We can now save it in different formats. In this unit, we will use the format *.net* because it is the one that is widey used in the scientific community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "bn_graphs.saveBN( bn, os.path.join('data', 'Asia.net'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To open the saved file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_saved = bn_graphs.loadBN(os.path.join('data','Asia.net'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferences in Bayesian Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilistic inference is the task of deriving the probability of one or more random variables taking a specific value or a specific set of values. For instance, we can use the Bayesian Network to *infer* the probability of the Lung Cancer being present given that a person Smokes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Pr( LungCancer = present | Smokes = present ) =~?$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, we need to choose an algorithm to perform probabilistic inferences. There are two was to accomplish this in python:\n",
    "- An exact method: **LazyPropagation**, which is usually applied for small networks\n",
    "- An approximate method: **Gibbs**, which is usually applied for large networks.\n",
    "\n",
    "In this unit, we will apply exact probabilistic methods, so we will use the **LazyPropagation** method. We can use it in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = bn_graphs.LazyPropagation(bn_saved)\n",
    "print(inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Without Evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inferenceswithout evidence are inferences in which you do not know anything about your decision scenario. All you variables are *unknown*. In other words, they are **not observed**. These are inferences of the type: whart is the probability of a person having Dispnea?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Pr( Dispnea = true ) =~?$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do this in Python in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference.makeInference()\n",
    "inference.posterior('Dispnea')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table tells us that without any further information about our decision scenario, John is very unlikely to hear the alarm ring, and consequenlty, he will not call the police!\n",
    "\n",
    "If you want to access these values individually, in Python, you proceed like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr( Dispnea = present)\n",
    "pr_Dispnea = inference.posterior('Dispnea')[0]\n",
    "print('Pr( Dispnea = prsent ) = ' + str(pr_Dispnea))\n",
    "\n",
    "# You can round this number to 4 decimal places\n",
    "print('Pr( Dispnea = present ) = ' + str(round(pr_Dispnea,4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.showProba(inference.posterior('Dispnea'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRY IT YOURSELF** \n",
    "Can you answer the following queries?\n",
    "$$Pr( Bronchitis = present ) =~?$$\n",
    "$$Pr( Tuberculosis = present ) =~?$$\n",
    "$$Pr( VisitAsia = present ) =~?$$\n",
    "$$Pr( PositiveXray = absent ) =~?$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:\n",
    "pr_Bronchitis_present = inference.posterior('Bronchitis')[0]\n",
    "print('Pr( Bronchitis = true ) = ' + str(round(pr_Bronchitis_present,4)))\n",
    "\n",
    "pr_Tuberculosis_absent = inference.posterior('Tuberculosis')[1]\n",
    "print('Pr( Tuberculosis = present ) = ' + str(round(pr_Tuberculosis_absent,4)))\n",
    "\n",
    "pr_VisitAsia_present = inference.posterior('VisitAsia')[0]\n",
    "print('Pr( VisitAsia = present ) = ' + str(round(pr_VisitAsia_present,4)))\n",
    "\n",
    "pr_PositiveXray_absent = inference.posterior('PositiveXray')[0]\n",
    "print('Pr( PositiveXray = absent ) = ' + str(round(pr_PositiveXray_absent,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.showProba(inference.posterior('Bronchitis'))\n",
    "gnb.showProba(inference.posterior('Tuberculosis'))\n",
    "gnb.showProba(inference.posterior('VisitAsia'))\n",
    "gnb.showProba(inference.posterior('PositiveXray'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference with Eviddence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian Networks also allow us to make more complex questions (or queries) to the network. For instance, let's imagine that we know that a person resently visited Asia. What is now the probability of that person tuberculosis given this additional piece of information (i.e. this piece of evidence)?\n",
    "\n",
    "$$Pr( Tuberculosis = present~|~VisitAsia = present ) =~?$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When we observe that an event occured, then we have a piece of evidence to give to our network.\n",
    "# We can specify this by using the function setEvidence() and by specifying the observed variable and its state:\n",
    "inference.setEvidence({'VisitAsia':'present'})\n",
    "\n",
    "# Then, we just make the inference as presented before\n",
    "inference.makeInference()\n",
    "inference.posterior('VisitAsia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.showProba(inference.posterior('Tuberculosis'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What happened to the probabilities? Knowing that a person went to Asia, what impact did this information cause in, for instance, the person getting Tuberculosis?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "Before we observed that a person Visited Asia, the probability of the person having tuberculosiswas:\n",
    "$$Pr( Tuberculosis = present ) = 1\\%$$\n",
    "\n",
    "After observing that a person has been in Asia, the probability of Tuberculosis increased to:\n",
    "$$Pr( Tuberculosis = present | VisitAsia = present ) = 5\\%$$\n",
    "Which is not very significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try it yourself** Knowing that a person has been in Asia recently and is shwing signs of shortness in breath (Dispnea), what happened to the probability distributions in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing All Inferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python also allows us to have a full visualizatin of the inferences of all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the full network when no variables are observed\n",
    "pyAgrum.lib.notebook.showInference( bn_saved )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the full network when we observe that John Called the police\n",
    "gnb.showInference( bn_saved, inference, {'Tuberculosis':'present'} )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Bayesian Network Using Existing Data - The Titanic Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conditional probability tables can be manually inderted into the Bayesian Network if we have this knowledge (which usually is acquired from experts and general statistics). However, most of the times, we have a dataset and we need to fill these conditional probability tables using that dataset. In this section, we will guide you on how to achieve this. Note that whether we manually fill these CPTs or if we learn them using existing data, the topology of the network must always be defined before hand!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the notebook, we will show how one could have used a Bayesian Network to model the Titanic datase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "import math\n",
    "import pyAgrum as gum\n",
    "import pyAgrum.lib.notebook as gnb\n",
    "from pyAgrum.lib.bn2roc import showROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook present three different Bayesien Networks techniques to answer the Kaggle Titanic challenge. The first approach we will answer the challenge without using the training set and we will only use our prior knowledge about shipwrecks. In the second approach we will only use the training set with pyAgrum's machine learning algorithms. Finally, in the third approach we will use both prior knowledge about shipwrecks and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretreatment of Data\n",
    "We will be using pandas to setup the learning data to fit with pyAgrum requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = pandas.read_csv(os.path.join('data', 'train.csv'))\n",
    "\n",
    "testdf = pandas.merge(pandas.read_csv(os.path.join('data', 'test.csv')),\n",
    "                    pandas.read_csv(os.path.join('data', 'gender_submission.csv')),\n",
    "                    on=\"PassengerId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This merges both the test base with the fact that a passager has survived or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in traindf.keys():\n",
    "    print('{0}: {1}'.format(k, len(traindf[k].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the number of unique values for each variable is necessary since Bayesian Networks are discrete models. We will want to reduce the domain size of some discrete varaibles (like age) and discretize continuous variables (like Fare).\n",
    "\n",
    "For starters you can filter out variables with a large number of values. Choosing a large number will have an impact on performances, which boils down to how much CPU and RAM you have at your disposal. Here, we choose to filter out any variable with more than 10 different outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in traindf.keys():\n",
    "    if len(traindf[k].unique())<=15:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leaves us with 6 variables, not much but still enough to learn a Bayesian Network. Will just add one more variable by reducing the cardinality of the Age variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf=pandas.merge(pandas.read_csv(os.path.join('data', 'test.csv')),\n",
    "                    pandas.read_csv(os.path.join('data', 'gender_submission.csv')),\n",
    "                    on=\"PassengerId\")\n",
    "\n",
    "def forAge(row):\n",
    "    try:\n",
    "        age = float(row['Age'])\n",
    "        if age < 1:\n",
    "            #return '[0;1['\n",
    "            return 'baby'\n",
    "        elif age < 6:\n",
    "            #return '[1;6['\n",
    "            return 'toddler'\n",
    "        elif age < 12:\n",
    "            #return '[6;12['\n",
    "            return 'kid'\n",
    "        elif age < 21:\n",
    "            #return '[12;21['\n",
    "            return 'teen'\n",
    "        elif age < 80:\n",
    "            #return '[21;80['\n",
    "            return 'adult'\n",
    "        else:\n",
    "            #return '[80;200]'\n",
    "            return 'old'\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "    \n",
    "def forBoolean(row, col):\n",
    "    try:\n",
    "        val = int(row[col])\n",
    "        if row[col] >= 1:\n",
    "            return \"True\"\n",
    "        else:\n",
    "            return \"False\"\n",
    "    except ValueError:\n",
    "        return \"False\"\n",
    "    \n",
    "def forGender(row):\n",
    "    if row['Sex'] == \"male\":\n",
    "        return \"Male\"\n",
    "    else:\n",
    "        return \"Female\"\n",
    "        \n",
    "\n",
    "testdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When pretreating data, you will want to wrap your changes inside a function, this will help you keep track of your changes and easily compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretreat(df):\n",
    "    if 'Survived' in df.columns:\n",
    "        df['Survived'] = df.apply(lambda row: forBoolean(row, 'Survived'), axis=1).dropna()\n",
    "    df['Age'] = df.apply(forAge, axis=1).dropna()\n",
    "    df['SibSp'] = df.apply(lambda row: forBoolean(row, 'SibSp'), axis=1).dropna()\n",
    "    df['Parch'] = df.apply(lambda row: forBoolean(row, 'Parch'), axis=1).dropna()\n",
    "    df['Sex'] = df.apply(forGender, axis=1).dropna()\n",
    "    droped_cols = [col for col in ['PassengerId', 'Name', 'Ticket', 'Fare', 'Cabin'] if col in df.columns]\n",
    "    df = df.drop(droped_cols, axis=1)\n",
    "    df = df.rename(index=str, columns={'Sex': 'Gender', 'SibSp': 'Siblings', 'Parch': 'Parents'})\n",
    "    return df\n",
    "\n",
    "traindf = pandas.read_csv(os.path.join('data', 'train.csv'))\n",
    "testdf  = pandas.merge(pandas.read_csv(os.path.join('data', 'test.csv')),\n",
    "                       pandas.read_csv(os.path.join('data', 'gender_submission.csv')),\n",
    "                       on=\"PassengerId\")\n",
    "traindf = pretreat(traindf)\n",
    "testdf = pretreat(testdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to save this intermediate learning database, since pyAgrum accepts only files as inputs. As a rule of thumb, save your CSV using comma as separators and do not quote values when you plan to use them with pyAgrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "traindf.to_csv(os.path.join('data', 'post_train.csv'), index=False)\n",
    "testdf.to_csv(os.path.join('data', 'post_test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] Pre-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now learn a Bayesian Network from the training set without any prior knowledge about shipwreks.\n",
    "\n",
    "Before learning a Bayesian Network, we first need to create a template. This is not mandatory, however it is sometimes usefull since not all varaibles values are present in the learning base (in this example the number of relatives).\n",
    "\n",
    "If during the learning step, the algorithm encounters an unknown value it will raise an error. This would be an issue if we wanted to automitize our classifier but, we will directly use values working with the test and learning base. This is not ideal but the objective here it to explore the data fast, not thoroughly.\n",
    "\n",
    "To help creating de the template Bayesian Network that we will use to learn our classifier, let us firt recall all the variables wa have at our disposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv(os.path.join('data', 'post_train.csv'))\n",
    "for k in traindf.keys():\n",
    "    print('{0}: {1}'.format(k, len(traindf[k].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=gum.BayesNet()\n",
    "template.add(gum.LabelizedVariable(\"Survived\", \"Survived\", ['False', 'True']))\n",
    "template.add(gum.RangeVariable(\"Pclass\", \"Pclass\",1,3))\n",
    "template.add(gum.LabelizedVariable(\"Gender\", \"The passenger's gender\",['Female', 'Male']))\n",
    "template.add(gum.LabelizedVariable(\"Siblings\", \"Siblings\",['False', 'True']))\n",
    "template.add(gum.LabelizedVariable(\"Parents\", \"Parents\",['False', 'True']))\n",
    "template.add(gum.LabelizedVariable(\"Embarked\", \"Embarked\", ['', 'C', 'Q', 'S']))\n",
    "template.add(gum.LabelizedVariable(\"Age\", \"The passenger's age category\", [\"baby\", \"toddler\", \"kid\", \"teen\", \"adult\", \"old\"]))             \n",
    "gnb.showBN(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning from data\n",
    "We can now learn our first Bayesian Network. As you will see, this is really easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join('data', 'post_train.csv')\n",
    "learner = gum.BNLearner(file, template)\n",
    "bn = learner.learnBN()\n",
    "bn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the Data\n",
    "\n",
    "Now that we have a BayesNet, we can start looking how the variables corelate with each other. pyAgum offer the perfect tool for that: the information graph.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.showInformation(bn,{},size=\"20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read this graph, you must understand what the entropy of a variable means: the hightest the value the more uncertain the variable marginal probability distrubition is (maximum entropy beging the equiprobable law). The lowest the value is, the more /certain/ the law is.\n",
    "\n",
    "A consequence of how entropy is calculated, is that entropy tends to get bigger if the random varaible has many modalities.\n",
    "\n",
    "What the information graph tells us is that the decade variable has a hight entropy. Thus, we can conclude that the passengers decade is distributed between all of its modalities.\n",
    "\n",
    "What it also tells us, it that high modality variables with low entropy, such as Parch or SibSp, are not evenly distributed.\n",
    "\n",
    "Let us look at he variables marginal probability by using the showInference() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.showInference(bn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The showInference() is really usefull as it shows the marginal probability distribution for each random variable of a BayesNet.\n",
    "\n",
    "We can now confirm what the entropy learned us: Parch and SibSp are unevenly distributed and decade is more evenly distributed.\n",
    "\n",
    "Lets focus on the Titanic challenge now, and look at the Survived variable. We show a single posterior using the showPosterior() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.showPosterior(bn,evs={},target='Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So more than 40% of the passenger in our learning database survived.\n",
    "\n",
    "So how can we use this BayesNet as a classifier ? Given a set of evidence, we can infer an update posterio distribution of the target variable Survived.\n",
    "\n",
    "Lets look at the odds of surviving as a man in his thirties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.showPosterior(bn,evs={\"Gender\": \"Male\", \"Age\": 'adult'},target='Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the odds of an old lady to survive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.showPosterior(bn,evs={\"Gender\": \"Female\", \"Age\": 'old'},target='Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, children and ladies first, that's right ?\n",
    "\n",
    "One last information we will need is which variables are required to predict the Survived variable. To do, we will use the markov blanket of Survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.sideBySide(bn, gum.MarkovBlanket(bn, 'Survived'), captions=[\"Learned Bayesian Network\", \"Markov blanket of 'Survived'\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Markov Blanket of the Survived variable tells us that we only need to observe Sex and Pclass in order to predict Survived. Not really usefull here but on larger Bayesian Networks it can save you a lot of time and CPU.\n",
    "\n",
    "So how to use this BayesNet we have learned as a classifier ? We simply infer the posterior the Survive variable given the set of evidence we are given, and if the passanger odds of survival are above some value he will be taged as a survivor.\n",
    "\n",
    "To compute the best value given the BayesNet and our training database, we can use the showROC() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showROC(bn, os.path.join('data', 'post_train.csv'), 'Survived', 'True', True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ie=gum.LazyPropagation(bn)\n",
    "init_belief(ie)\n",
    "ie.addTarget('Survived')\n",
    "result = testdf.apply(lambda x: is_well_predicted(ie, bn, 0.157935, x), axis=1)\n",
    "result.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = sum(result.map(lambda x: 1 if x.startswith(\"True\") else 0 ))\n",
    "total = result.count()\n",
    "print(\"{0:.2f}% good predictions\".format(positives/total*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3] Making a BN without learning data\n",
    "\n",
    "In this last part we will combine both methods: we will force the BayesNet DAG and learn its parameters. We will assume the naive bayes hypothesis, which states that all random variables are independant conditionally to the target variable (here the variable Survived).\n",
    "\n",
    "This results in the following topology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = gum.BayesNet(\"Surviving Titanic\")\n",
    "bn.add(survived)\n",
    "bn.add(age)\n",
    "bn.add(gender)\n",
    "bn.add(siblings)\n",
    "bn.add(parents)\n",
    "bn.addArc('Survived', 'Age')\n",
    "bn.addArc('Survived', 'Gender')\n",
    "bn.addArc('Survived', 'Siblings')\n",
    "bn.addArc('Survived', 'Parents')\n",
    "bn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to learn the parameters, this can easily be done using the learnParameters method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = gum.BNLearner(os.path.join(\"data\", 'post_train.csv'), bn)\n",
    "bn = learner.learnParameters(bn.dag())\n",
    "gnb.showInference(bn, size=\"10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we compare the CPTs obtained here with those defined by our expert in the first example we can see that they differ. They ressemble those obtained in the second example. This result is expected since we have learn the parameters from the training data, the learned probabilities distribution should match the data.\n",
    "\n",
    "The final steps consists of confronting this model agains our test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showROC(bn, os.path.join('data', 'post_train.csv'), 'Survived', \"True\", True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = gum.LazyPropagation(bn)\n",
    "init_belief(ie)\n",
    "ie.addTarget('Survived')\n",
    "result = testdf.apply(lambda x: is_well_predicted(ie, bn, 0.35917266477065596, x), axis=1)\n",
    "result.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = sum(result.map(lambda x: 1 if x.startswith(\"True\") else 0 ))\n",
    "total = result.count()\n",
    "print(\"{0:.2f}% good predictions\".format(positives/total*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes perform well when used for classification tasks, as shown by the 95% of good predictions achieved by our third model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have demonstradted with different classification techniques using Bayesian Networks. In the first approach, we mangaged to model a classifier without using any training set and relying solely on prior knowledge. In the second approach we used only machine learning techniques. Finally, in the third example we assumed the naive bayes hypothesis and obtained a model combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it yourlself!\n",
    "\n",
    "Try to model the following network and come up with some analysis.\n",
    "\n",
    "Scenario: You have a burglar alarm that is sometimes set off by minor earthquakes. You have two neighbours, John and Mary, who promised to call you if they hear the alarm.\n",
    "\n",
    "Example of an inference task: suppose Mary calls you, but John does not, what is the probability that a burglary occured in your house?\n",
    "\n",
    "<img src = \"images/burglar_bn.png\" width=\"500px\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
